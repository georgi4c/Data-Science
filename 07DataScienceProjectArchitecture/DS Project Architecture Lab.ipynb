{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nose.tools import *\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Write your imports here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "525f2882f2b6e191652899e33517abb4",
     "grade": false,
     "grade_id": "cell-1b7f77949e7a3450",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Data Science Project Architecture Lab\n",
    "## End-to-end project: demonstrating the power of OSEMN. Transition towards modelling. Machine learning basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "On 15 April 1912, the Titanic sank after colliding with an iceberg, killing more than two thirds of the crew and passengers. The dataset provided for you in the `data/` folder contains information about the passengers onboard and which of them survived.\n",
    "\n",
    "The goal of this lab is to explore the data, prepare it for modelling, and perform a (kind of) simple classification. We'll also explore some basics of practical machine learning such as data preparation, testing and training sets, and model evaluation.\n",
    "\n",
    "The original dataset is located [here](https://www.kaggle.com/c/titanic/data). You can read the page for more information about the data and variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1. Read the dataset (1 point)\n",
    "Read the dataset in the `data/titanic.csv` file into the `titanic_data` variable. Here's a short description of what each column means:\n",
    "* PassengerId - a unique number identifying each passenger\n",
    "* Survived - indicator variable: 1 if the passenger survived, 0 otherwise\n",
    "* Pclass - passenger ticket class (1, 2 or 3). This can be used as an indicator of wealth\n",
    "* Name\n",
    "* Sex\n",
    "* Age\n",
    "* SibSp - number of siblings / spouses aboard the Titanic\n",
    "* Parch - number of parents / children aboard the Titanic\n",
    "* Ticket - ticket number\n",
    "* Fare - passenger fare (price)\n",
    "* Cabin - cabin number\n",
    "* Embarked - port of embarkation: C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "**Notes on family relationships:**\n",
    "* Sibling = brother, sister, stepbrother, stepsister\n",
    "* Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
    "* Parent = mother, father\n",
    "* Child = daughter, son, stepdaughter, stepson. Some children travelled only with a nanny, therefore Parch = 0 for them.\n",
    "\n",
    "Set the index column to be \"PassengerId\". Rename \"Pclass\" to \"Class\" and \"Parch\" to \"ParCh\". Other than that, the column names aren't too bad (although not Pythonic enough). Don't rename them.\n",
    "\n",
    "Also, change the \"Embarked\" column to include the full names of the ports (see the column descriptions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9f7e61b1a2b4b2484ae37f526f0a863f",
     "grade": false,
     "grade_id": "cell-8d05536388210811",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv(\"data/titanic.csv\", index_col=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.rename(columns={'Pclass': 'Class', 'Parch': 'ParCh'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_full_port_name(symbol):\n",
    "    if symbol == \"C\":\n",
    "        return \"Cherbourg\"\n",
    "    elif symbol == \"Q\":\n",
    "        return \"Queenstown\"\n",
    "    elif symbol == \"S\":\n",
    "        return \"Southampton\"\n",
    "    else:\n",
    "        return symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.Embarked = titanic_data.Embarked.apply(map_to_full_port_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>ParCh</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Flynn, Mr. John Irwin (\"Irving\")</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17474</td>\n",
       "      <td>26.3875</td>\n",
       "      <td>E25</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Moussa, Mrs. (Mantoura Boulos)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2626</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Seward, Mr. Frederic Kimber</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113794</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Fischer, Mr. Eberhard Thelander</td>\n",
       "      <td>male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350036</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mitkoff, Mr. Mito</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349221</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>McKane, Mr. Peter David</td>\n",
       "      <td>male</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28403</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Francatelli, Miss. Laura Mabel</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17485</td>\n",
       "      <td>56.9292</td>\n",
       "      <td>E36</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pears, Mrs. Thomas (Edith Wearne)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113776</td>\n",
       "      <td>66.6000</td>\n",
       "      <td>C2</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Van Impe, Mr. Jean Baptiste</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>345773</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Milling, Mr. Jacob Christian</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234360</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bryhl, Mr. Kurt Arnold Gottfrid</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>236853</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Lehmann, Miss. Bertha</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SC 1748</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LeRoy, Miss. Bertha</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17761</td>\n",
       "      <td>106.4250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Leinonen, Mr. Antti Gustaf</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101292</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Berglund, Mr. Karl Ivar Sven</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PP 4348</td>\n",
       "      <td>9.3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Mellinger, Mrs. (Elizabeth Anne Maidment)</td>\n",
       "      <td>female</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250644</td>\n",
       "      <td>19.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Appleton, Mrs. Edward Dale (Charlotte Lamson)</td>\n",
       "      <td>female</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11769</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>C101</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Thorneycroft, Mr. Percival</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>376564</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ling, Mr. Lee</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1601</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Holverson, Mr. Alexander Oskar</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113789</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Buss, Miss. Kate</td>\n",
       "      <td>female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27849</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Slocovski, Mr. Selman Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392086</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Lulic, Mr. Nikola</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315098</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bazzani, Miss. Albina</td>\n",
       "      <td>female</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11813</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>D15</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Pasic, Mr. Jakob</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315097</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ford, Miss. Doolina Margaret \"Daisy\"</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6608</td>\n",
       "      <td>34.3750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Sobey, Mr. Samuel James Hayden</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 29178</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Klasen, Mr. Klas Albin</td>\n",
       "      <td>male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>350404</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Class                                           Name  \\\n",
       "PassengerId                                                                   \n",
       "573                 1      1               Flynn, Mr. John Irwin (\"Irving\")   \n",
       "368                 1      3                 Moussa, Mrs. (Mantoura Boulos)   \n",
       "448                 1      1                    Seward, Mr. Frederic Kimber   \n",
       "689                 0      3                Fischer, Mr. Eberhard Thelander   \n",
       "651                 0      3                              Mitkoff, Mr. Mito   \n",
       "398                 0      2                        McKane, Mr. Peter David   \n",
       "310                 1      1                 Francatelli, Miss. Laura Mabel   \n",
       "152                 1      1              Pears, Mrs. Thomas (Edith Wearne)   \n",
       "596                 0      3                    Van Impe, Mr. Jean Baptiste   \n",
       "464                 0      2                   Milling, Mr. Jacob Christian   \n",
       "729                 0      2                Bryhl, Mr. Kurt Arnold Gottfrid   \n",
       "390                 1      2                          Lehmann, Miss. Bertha   \n",
       "538                 1      1                            LeRoy, Miss. Bertha   \n",
       "637                 0      3                     Leinonen, Mr. Antti Gustaf   \n",
       "226                 0      3                   Berglund, Mr. Karl Ivar Sven   \n",
       "273                 1      2      Mellinger, Mrs. (Elizabeth Anne Maidment)   \n",
       "572                 1      1  Appleton, Mrs. Edward Dale (Charlotte Lamson)   \n",
       "640                 0      3                     Thorneycroft, Mr. Percival   \n",
       "170                 0      3                                  Ling, Mr. Lee   \n",
       "36                  0      1                 Holverson, Mr. Alexander Oskar   \n",
       "388                 1      2                               Buss, Miss. Kate   \n",
       "88                  0      3                  Slocovski, Mr. Selman Francis   \n",
       "3                   1      3                         Heikkinen, Miss. Laina   \n",
       "822                 1      3                              Lulic, Mr. Nikola   \n",
       "219                 1      1                          Bazzani, Miss. Albina   \n",
       "7                   0      1                        McCarthy, Mr. Timothy J   \n",
       "837                 0      3                               Pasic, Mr. Jakob   \n",
       "437                 0      3           Ford, Miss. Doolina Margaret \"Daisy\"   \n",
       "135                 0      2                 Sobey, Mr. Samuel James Hayden   \n",
       "176                 0      3                         Klasen, Mr. Klas Albin   \n",
       "\n",
       "                Sex   Age  SibSp  ParCh             Ticket      Fare Cabin  \\\n",
       "PassengerId                                                                  \n",
       "573            male  36.0      0      0           PC 17474   26.3875   E25   \n",
       "368          female   NaN      0      0               2626    7.2292   NaN   \n",
       "448            male  34.0      0      0             113794   26.5500   NaN   \n",
       "689            male  18.0      0      0             350036    7.7958   NaN   \n",
       "651            male   NaN      0      0             349221    7.8958   NaN   \n",
       "398            male  46.0      0      0              28403   26.0000   NaN   \n",
       "310          female  30.0      0      0           PC 17485   56.9292   E36   \n",
       "152          female  22.0      1      0             113776   66.6000    C2   \n",
       "596            male  36.0      1      1             345773   24.1500   NaN   \n",
       "464            male  48.0      0      0             234360   13.0000   NaN   \n",
       "729            male  25.0      1      0             236853   26.0000   NaN   \n",
       "390          female  17.0      0      0            SC 1748   12.0000   NaN   \n",
       "538          female  30.0      0      0           PC 17761  106.4250   NaN   \n",
       "637            male  32.0      0      0  STON/O 2. 3101292    7.9250   NaN   \n",
       "226            male  22.0      0      0            PP 4348    9.3500   NaN   \n",
       "273          female  41.0      0      1             250644   19.5000   NaN   \n",
       "572          female  53.0      2      0              11769   51.4792  C101   \n",
       "640            male   NaN      1      0             376564   16.1000   NaN   \n",
       "170            male  28.0      0      0               1601   56.4958   NaN   \n",
       "36             male  42.0      1      0             113789   52.0000   NaN   \n",
       "388          female  36.0      0      0              27849   13.0000   NaN   \n",
       "88             male   NaN      0      0    SOTON/OQ 392086    8.0500   NaN   \n",
       "3            female  26.0      0      0   STON/O2. 3101282    7.9250   NaN   \n",
       "822            male  27.0      0      0             315098    8.6625   NaN   \n",
       "219          female  32.0      0      0              11813   76.2917   D15   \n",
       "7              male  54.0      0      0              17463   51.8625   E46   \n",
       "837            male  21.0      0      0             315097    8.6625   NaN   \n",
       "437          female  21.0      2      2         W./C. 6608   34.3750   NaN   \n",
       "135            male  25.0      0      0         C.A. 29178   13.0000   NaN   \n",
       "176            male  18.0      1      1             350404    7.8542   NaN   \n",
       "\n",
       "                Embarked  \n",
       "PassengerId               \n",
       "573          Southampton  \n",
       "368            Cherbourg  \n",
       "448          Southampton  \n",
       "689          Southampton  \n",
       "651          Southampton  \n",
       "398          Southampton  \n",
       "310            Cherbourg  \n",
       "152          Southampton  \n",
       "596          Southampton  \n",
       "464          Southampton  \n",
       "729          Southampton  \n",
       "390            Cherbourg  \n",
       "538            Cherbourg  \n",
       "637          Southampton  \n",
       "226          Southampton  \n",
       "273          Southampton  \n",
       "572          Southampton  \n",
       "640          Southampton  \n",
       "170          Southampton  \n",
       "36           Southampton  \n",
       "388          Southampton  \n",
       "88           Southampton  \n",
       "3            Southampton  \n",
       "822          Southampton  \n",
       "219            Cherbourg  \n",
       "7            Southampton  \n",
       "837          Southampton  \n",
       "437          Southampton  \n",
       "135          Southampton  \n",
       "176          Southampton  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.sample(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f2593c9c3a6fb7e30c59ff555f621201",
     "grade": true,
     "grade_id": "cell-eeefe71b639dffe8",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(titanic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. Inspect and fill missing data (1 point)\n",
    "See how many records are missing for each column. You can just execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Class     891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       714 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   ParCh     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     204 non-null    object \n",
      " 10  Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that most of the data is there. We have some people with unknown ages and two people with unknown embarkation ports.\n",
    "\n",
    "For missing ages, there are three approaches. We can't say right now which will prove the most correct but we'll stick to one.\n",
    "* Remove people with unknown ages - not desirable, since they are many\n",
    "* Replace unknown ages with a \"centinel\" value, e.g. $-1$ - not desirable because this will introduce invalid data which may throw our models off \n",
    "* Replace unknown ages with the column mean\n",
    "\n",
    "We'll stick with the third approach. Replace the `NaN` values in the `Age` column with the column mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "03704d4a37ab89e1ae20c7b07a8dca02",
     "grade": false,
     "grade_id": "cell-cda0e1f62b8fa17e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(titanic_data.Age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age = round(titanic_data.Age.mean())\n",
    "titanic_data.Age = titanic_data.Age.fillna(mean_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>ParCh</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Danoff, Mr. Yoto</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349219</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Denkoff, Mr. Mitto</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349225</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Garside, Miss. Ethel</td>\n",
       "      <td>female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243880</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Mrs. Nils (Alma Cornelia Berglund)</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Williams-Lambert, Mr. Fletcher Fellows</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113510</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>C128</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ivanoff, Mr. Kanio</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349201</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Banfield, Mr. Frederick James</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A./SOTON 34068</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Maenpaa, Mr. Matti Alexanteri</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101275</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Doling, Miss. Elsie</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>231919</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230433</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Hart, Mr. Benjamin</td>\n",
       "      <td>male</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>F.C.C. 13529</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Danbom, Mr. Ernst Gilbert</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347080</td>\n",
       "      <td>14.4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Olsen, Mr. Ole Martin</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fa 265302</td>\n",
       "      <td>7.3125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Hold, Mr. Stephen</td>\n",
       "      <td>male</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26707</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Brocklebank, Mr. William Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364512</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Kirkland, Rev. Charles Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>219533</td>\n",
       "      <td>12.3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ostby, Mr. Engelhart Cornelius</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113509</td>\n",
       "      <td>61.9792</td>\n",
       "      <td>B30</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Mellinger, Miss. Madeleine Violet</td>\n",
       "      <td>female</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250644</td>\n",
       "      <td>19.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Clifford, Mr. George Quincy</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110465</td>\n",
       "      <td>52.0000</td>\n",
       "      <td>A14</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Class                                          Name  \\\n",
       "PassengerId                                                                  \n",
       "322                 0      3                              Danoff, Mr. Yoto   \n",
       "336                 0      3                            Denkoff, Mr. Mitto   \n",
       "577                 1      2                          Garside, Miss. Ethel   \n",
       "568                 0      3   Palsson, Mrs. Nils (Alma Cornelia Berglund)   \n",
       "352                 0      1        Williams-Lambert, Mr. Fletcher Fellows   \n",
       "739                 0      3                            Ivanoff, Mr. Kanio   \n",
       "884                 0      2                 Banfield, Mr. Frederick James   \n",
       "244                 0      3                 Maenpaa, Mr. Matti Alexanteri   \n",
       "652                 1      2                           Doling, Miss. Elsie   \n",
       "881                 1      2  Shelley, Mrs. William (Imanita Parrish Hall)   \n",
       "315                 0      2                            Hart, Mr. Benjamin   \n",
       "617                 0      3                     Danbom, Mr. Ernst Gilbert   \n",
       "155                 0      3                         Olsen, Mr. Ole Martin   \n",
       "237                 0      2                             Hold, Mr. Stephen   \n",
       "615                 0      3               Brocklebank, Mr. William Alfred   \n",
       "627                 0      2                Kirkland, Rev. Charles Leonard   \n",
       "55                  0      1                Ostby, Mr. Engelhart Cornelius   \n",
       "447                 1      2             Mellinger, Miss. Madeleine Violet   \n",
       "27                  0      3                       Emir, Mr. Farred Chehab   \n",
       "476                 0      1                   Clifford, Mr. George Quincy   \n",
       "\n",
       "                Sex   Age  SibSp  ParCh             Ticket     Fare Cabin  \\\n",
       "PassengerId                                                                 \n",
       "322            male  27.0      0      0             349219   7.8958   NaN   \n",
       "336            male  30.0      0      0             349225   7.8958   NaN   \n",
       "577          female  34.0      0      0             243880  13.0000   NaN   \n",
       "568          female  29.0      0      4             349909  21.0750   NaN   \n",
       "352            male  30.0      0      0             113510  35.0000  C128   \n",
       "739            male  30.0      0      0             349201   7.8958   NaN   \n",
       "884            male  28.0      0      0   C.A./SOTON 34068  10.5000   NaN   \n",
       "244            male  22.0      0      0  STON/O 2. 3101275   7.1250   NaN   \n",
       "652          female  18.0      0      1             231919  23.0000   NaN   \n",
       "881          female  25.0      0      1             230433  26.0000   NaN   \n",
       "315            male  43.0      1      1       F.C.C. 13529  26.2500   NaN   \n",
       "617            male  34.0      1      1             347080  14.4000   NaN   \n",
       "155            male  30.0      0      0          Fa 265302   7.3125   NaN   \n",
       "237            male  44.0      1      0              26707  26.0000   NaN   \n",
       "615            male  35.0      0      0             364512   8.0500   NaN   \n",
       "627            male  57.0      0      0             219533  12.3500   NaN   \n",
       "55             male  65.0      0      1             113509  61.9792   B30   \n",
       "447          female  13.0      0      1             250644  19.5000   NaN   \n",
       "27             male  30.0      0      0               2631   7.2250   NaN   \n",
       "476            male  30.0      0      0             110465  52.0000   A14   \n",
       "\n",
       "                Embarked  \n",
       "PassengerId               \n",
       "322          Southampton  \n",
       "336          Southampton  \n",
       "577          Southampton  \n",
       "568          Southampton  \n",
       "352          Southampton  \n",
       "739          Southampton  \n",
       "884          Southampton  \n",
       "244          Southampton  \n",
       "652          Southampton  \n",
       "881          Southampton  \n",
       "315          Southampton  \n",
       "617          Southampton  \n",
       "155          Southampton  \n",
       "237          Southampton  \n",
       "615          Southampton  \n",
       "627           Queenstown  \n",
       "55             Cherbourg  \n",
       "447          Southampton  \n",
       "27             Cherbourg  \n",
       "476          Southampton  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.sample(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect missing embarkation ports. Store the passengers with unknown embarkation ports in the provided variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "10acfa449e026fa555c709469ad0f7eb",
     "grade": false,
     "grade_id": "cell-c81adf03dbc34dba",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>ParCh</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Class                                       Name  \\\n",
       "PassengerId                                                               \n",
       "62                  1      1                        Icard, Miss. Amelie   \n",
       "830                 1      1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "                Sex   Age  SibSp  ParCh  Ticket  Fare Cabin Embarked  \n",
       "PassengerId                                                           \n",
       "62           female  38.0      0      0  113572  80.0   B28      NaN  \n",
       "830          female  62.0      0      0  113572  80.0   B28      NaN  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passengers_with_unknown_embarkation_ports = titanic_data[titanic_data.Embarked.isnull()]\n",
    "passengers_with_unknown_embarkation_ports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are two such passengers with the same ticket. We can check there are no other passengers with the same ticket number. We have no idea what to do but we might just replace them with the most common embarkation port.\n",
    "\n",
    "Find out which port was the most common. Replace the two NaN values in the dataset with this port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "741792adac4959231666ba263fe30166",
     "grade": false,
     "grade_id": "cell-bd2f821dd9cb5fc9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "most_common_port = titanic_data.groupby(\"Embarked\").Embarked.count().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.Embarked = titanic_data.Embarked.fillna(most_common_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "85b021c52a9b2d0f0daa3f112e9f00ff",
     "grade": true,
     "grade_id": "cell-50f02a8a39bf9d82",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for all operations\n",
    "assert_false(titanic_data.Age.isnull().any())\n",
    "\n",
    "assert_is_not_none(passengers_with_unknown_embarkation_ports)\n",
    "assert_is_not_none(most_common_port)\n",
    "assert_false(titanic_data.Embarked.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3. Remove unnecessary columns (1 point)\n",
    "The `Cabin` column contains too many missing values. Probably the best we can do with it is remove it. Also, the names and ticket numbers might be useful in another analysis, but not in this case. We're interested in which passengers survived and we have no reason to think that their names might be related to their survival rate. Also, the ticket numbers are somewhat random.\n",
    "\n",
    "**Note:** It might be interesting to extract the titles of the passengers (e.g. \"Mr.\", \"Miss\", \"Dr.\", etc.) and see whether it correlates to survival rate (e.g. people with higher social status might be more likely to get a boat and survive). But let's not focus on this right now. The class and ticket fare are good enough to indicate social status / wealth.\n",
    "\n",
    "Remove the `Cabin`, `Name`, and `Ticket` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "10490df105b93dffee0e19d79e3bbe1a",
     "grade": false,
     "grade_id": "cell-4d96142a29f5f032",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "titanic_data = titanic_data.drop(columns=[\"Cabin\", \"Name\", \"Ticket\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Class</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>ParCh</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Class     Sex   Age  SibSp  ParCh     Fare     Embarked\n",
       "PassengerId                                                                   \n",
       "1                   0      3    male  22.0      1      0   7.2500  Southampton\n",
       "2                   1      1  female  38.0      1      0  71.2833    Cherbourg\n",
       "3                   1      3  female  26.0      0      0   7.9250  Southampton\n",
       "4                   1      1  female  35.0      1      0  53.1000  Southampton\n",
       "5                   0      3    male  35.0      0      0   8.0500  Southampton"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a6743518d8895b2a77bed489ef09cf7f",
     "grade": true,
     "grade_id": "cell-ce236d7fee7f5854",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(titanic_data.shape, (891, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4. Explore the data: single variables (1 point)\n",
    "Let's start with visualizing single variables. \n",
    "\n",
    "Try plotting a histogram of all ages with 20 bins. You'll see a kind of unusual peak. Remember that this is because we filled in the missing data with the mean of all ages, and it happens to be right where that peak is.\n",
    "\n",
    "Also, try plotting a bar chart (or a pie chart) showing the number of passengers who are male and female. To do this, group the dataset by sex and count the number of rows for each group. `num_passengers_by_sex` should be a `pd.Series` with  two indices: \"male\" and \"female\".\n",
    "\n",
    "Finally, try plotting a histogram of fares to see how asymmetric they are.\n",
    "\n",
    "**Note:** The plots are not autograded, only the data. Feel free to change them, experiment, and add more plots as you see fit. I had quite a lot of fun playing around with different aspects of the data. This is the reason to have EDA, after all :).\n",
    "\n",
    "**Note 2:** The variables should be really simple to set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ec5f395304a7be79124827f79c7d63ec",
     "grade": false,
     "grade_id": "cell-2c3caaa38c49514a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "all_ages = None\n",
    "num_passengers_by_sex = None\n",
    "all_fares = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "plt.hist(all_ages, bins = 20)\n",
    "plt.title(\"Distribution of ages\")\n",
    "plt.show()\n",
    "\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.pie(num_passengers_by_sex, labels = num_passengers_by_sex.index, autopct = \"%.2f%%\")\n",
    "plt.title(\"Passengers per sex\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(all_fares, bins = 20)\n",
    "plt.title(\"Distribution of fares\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "99e106190db24b727147d398e2014fdd",
     "grade": true,
     "grade_id": "cell-1e84086c6a0454d7",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(all_ages)\n",
    "assert_is_not_none(num_passengers_by_sex)\n",
    "assert_is_not_none(all_fares)\n",
    "\n",
    "assert_equal(len(all_ages), len(all_fares))\n",
    "assert_equal(num_passengers_by_sex.index.tolist(), [\"female\", \"male\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5. Explore correlations in the dataset (1 point)\n",
    "We can play a lot with single variables, groups, etc. But let's focus on correlations now.\n",
    "\n",
    "One of the first things we can do is check all correlations on all variables, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there are some correlations but it seems nothing too interesting can be found.\n",
    "\n",
    "Let's now try some groupings. For example, what percentage of each gender survived? Recall that we calculated the total number of passengers for each gender in the previous exercise.\n",
    "\n",
    "Filter the `titanic_data` dataset to get only survived passengers and apply the same grouping and counting as you did in the previous exercise. You should get a series with \"male\" and \"female\" as the indices.\n",
    "\n",
    "If your answers are correct, the `print()` statements should run without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6879abb15cfadda4f2b309d3c4932c25",
     "grade": false,
     "grade_id": "cell-7554388a9c07ce6f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "survived_passengers = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(\"Survived men: {} / {}, {:.2f}%\".format(survived_passengers.male, num_passengers_by_sex.male, survived_passengers.male / num_passengers_by_sex.male * 100))\n",
    "print(\"Survived women: {} / {}, {:.2f}%\".format(survived_passengers.female, num_passengers_by_sex.female, survived_passengers.female / num_passengers_by_sex.female * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a far greater proportion of women survived. This is really significant for two reasons: 1) the difference is really large (74% women vs. 19% men survived), 2) the total number of women on board is smaller.\n",
    "\n",
    "We can therefore conclude that women have been given advantage while evacuating from the ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "916a87e6ebac9119d853b000127a150d",
     "grade": true,
     "grade_id": "cell-508e9ba1aadd8279",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(survived_passengers)\n",
    "assert_equal(num_passengers_by_sex.index.tolist(), [\"female\", \"male\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to look for more correlations if you wish.\n",
    "\n",
    "Let's now focus on something else: the distribution of ages broken down by class. As we already mentioned, passenger class can be used as a proxy for a person's wealth.\n",
    "\n",
    "Group the dataset by class and extract the ages for each group. Store this in the `ages_by_class` variable. It should be a `pd.Series` with `Class` as the index.\n",
    "\n",
    "Plot a histogram showing the three age distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "48fd907f7319418f61746d633edb516a",
     "grade": false,
     "grade_id": "cell-b0f18ef015029cc9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ages_by_class = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this is not an autograded cell. It's here only to help you \n",
    "# find out whether your answer and data format are correct\n",
    "assert_is_not_none(ages_by_class)\n",
    "assert_equal(ages_by_class.size().tolist(), [216, 184, 491])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for passenger_class, ages in ages_by_class:\n",
    "    plt.hist(ages, label = \"Class {}\".format(passenger_class), alpha = 0.7)\n",
    "plt.title(\"Distribution of passenger ages per class\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see something really interesting. It seems that first-class passengers are a little bit older than third-class passengers. But is this really true? We can't tell for sure. First of all, there are many more third-class passengers; and second, we can't be sure whether there's a significant difference or not.\n",
    "\n",
    "Fortunately, there's a rigorous statistical method to find out. Enter **hypothesis testing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6. Perform hypothesis testing on age vs. class (1 point)\n",
    "First, let's store \"class 1\" and \"class 3\" passenger ages in their own variables, for easier work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_class_ages = ages_by_class.get_group(1)\n",
    "third_class_ages = ages_by_class.get_group(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform a hypothesis test, we'll need a hypothesis. Actually, a pair of hypotheses. The \"null hypothesis\", $H_0$ says that \"there's nothing interesting going on with the data\". The \"alternative hypothesis\", $H_1$ says the opposite.\n",
    "\n",
    "We want to prove whether or not the passenger class is correlated with the age. Therefore:\n",
    "* $H_0:$ Passenger class is not correlated with age. `first_class_ages` and `third_class_ages` are two samples from the same distribution.\n",
    "* $H_1:$ `first_class_ages` and `third_class_ages` come from two different distributions.\n",
    "\n",
    "Ideally, **we'd like to reject the null hypothesis**.\n",
    "\n",
    "Here's a quick explanation of the process: we'll perform a test. The exact details aren't important. We assume that $H_0$ is true, therefore **the differences between the two histograms occur simply by chance**. The test will return a $p$-value. It corresponds to the probability that we observe **as extreme or more extreme differences** between the two histograms if $H_0$ is really true.\n",
    "\n",
    "We have to agree on a \"threshold value\" of $p$. Usually that's 5% (0.05), but let's choose 1% in this case. What does this mean? If we reject $H_0$, there will still be 1% chance that we rejected it wrongly.\n",
    "\n",
    "**If $p\\le1\\%$, we will reject $H_0$**.\n",
    "\n",
    "To compare the two variables, it's easiest to perform what's called a **t-test**. It's already been imported for you. Call it like this: `test_result = ttest_ind(<first_variable>, <second_variable>, equal_var = False)`.\n",
    "\n",
    "**Note:** You can get additional information about the mechanics of statistical hypothesis testing on the Internet. Research more if you wish. You can also research what `equal_var = False` is and why we aren't allowed to assume equal variances in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c82e076dc2c993efb3542dad12387637",
     "grade": false,
     "grade_id": "cell-2fad87583bb70604",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "test_result = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(test_result.pvalue)\n",
    "if test_result.pvalue <= 0.01:\n",
    "    print(\"The differences in age are significant. Reject H0.\")\n",
    "else:\n",
    "    print(\"There's not enough evidence to reject H0. Don't accept or reject anything else.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "71d34f381017f96f87caee725da0dcd3",
     "grade": true,
     "grade_id": "cell-7ce2e934e8d8ecb9",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we can conclude that **the distributions of ages are significantly different at the 1% level**. Actually, they're so significantly different, that we might as well have chosen $1.10^{-17}\\%$ and still be correct.\n",
    "\n",
    "This means that ages are different for the different classes. How can we interpret this? Probably wealthier people are older. Younger people might not need, or might not be able to afford, a higher fare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7. Prepare the data for modelling: indicator variables (1 point)\n",
    "We're going to use `scikit-learn` to model the data. However, that's not so simple. We first need to preprocess the data a little.\n",
    "\n",
    "Most importantly, all variables should be numeric. `scikit-learn` doesn't know how to deal with text and categories.\n",
    "\n",
    "We need to convert `Sex` and `Embarked` to categories. There are many ways to do that.\n",
    "\n",
    "What's considered the best way is via the so-called \"indicator variables\". These are variables whose values are 0 or 1. For example, let's look at the \"Sex\" column. It has two possible values: \"male\" and \"female\". Each of these values will create a new column: `Sex_male` and `Sex_female`. If the passenger is male, he will have 1 in the `Sex_male` column, and so on. Similarly, with `Embarked`.\n",
    "\n",
    "There's a really easy way to do this in `pandas`: `pd.get_dummies(dataframe)`. Note that this returns another dataframe. Add the columns: `[\"Class\", \"Sex\", \"Embarked\"]` to the dataframe. Write the code and explore the newly created dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "579bcc593b53a883fd0f76395615a091",
     "grade": false,
     "grade_id": "cell-ce48a98dc2da3cce",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "titanic_data_for_modelling = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "titanic_data_for_modelling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that we have more columns. We can also see that since `Sex` has only two possible values, the two columns `Sex_female` and `Sex_male` are just opposites of each other. We can safely remove one of them. However, this is not true for the `Class` and `Embarked` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3f3a74b69ef3afa7e884a482683a1822",
     "grade": false,
     "grade_id": "cell-eb71a6ae99067bb1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "755132340ca2abe54bf54c8f217dabbd",
     "grade": true,
     "grade_id": "cell-cf11c03fee894a9c",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(titanic_data_for_modelling.shape, (891, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, it will be really convenient to separate the explanatory variables from the target variable.\n",
    "\n",
    "We want to predict whether or not a person has survived. Therefore, `Survived` will be our target variable. All other variables will be our explanatory variables (also called features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data_features = titanic_data_for_modelling.drop(\"Survived\", axis = 1)\n",
    "titanic_data_target = titanic_data_for_modelling.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8. Prepare the data for modelling: normalization (1 point)\n",
    "In order for the model to perform better, we usually need to rescale the values for each numeric column. \n",
    "\n",
    "Why do we do this? It's related to algorithm stability and convergence. Generally, a machine learning algorithm will perform better if all values are in similar ranges.\n",
    "\n",
    "Do we always need it? No, but we usually do.\n",
    "\n",
    "There are many types of normalization. In this case, we're going to use a **min-max normalization**. The minimum value in the column will become 0, the maximum will become 1. All values in between will be scaled accordingly.\n",
    "\n",
    "`scikit-learn` has a very convenient [MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler). You use it by simply instantiating it and passing the data:\n",
    "```python\n",
    "scaler = MinMaxScaler()\n",
    "titanic_data_features_scaled = scaler.fit_transform(titanic_data_features)\n",
    "```\n",
    "\n",
    "Note that `titanic_data_scaled` will be a 2D `numpy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "da2b97f020a5c62730728fe988fefba8",
     "grade": false,
     "grade_id": "cell-15df658fa2716e19",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "titanic_data_scaled = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "183dbb5a7ba39784d3bdc9af8cdddcf2",
     "grade": true,
     "grade_id": "cell-8290e1e8c30f5922",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(titanic_data_features_scaled)\n",
    "assert_equal(titanic_data_features_scaled.shape, (891, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9. Split the data (0 points)\n",
    "When we want to evaluate a machine learning model, we usually hide some data from it. We train the model on most of the data, but when we test it afterwards, we pass the additional, hidden data. This is similar to how humans learn - a teacher won't give the exact answers to all students. If this was the case, the teacher cannot know whether a student really learned something, or just memorized all the answers.\n",
    "\n",
    "The function `train_test_split` from `scikit-learn` will perform the splitting for us. See the docs [here](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "We usually want $\\approx 70\\%$ of the data for training and the remaining $\\approx 30\\%$ for testing. It's very important that the data is shuffled. `train_test_split()` will do this by default.\n",
    "\n",
    "We'll pass the features and target variables and we'll get the different parts accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    titanic_data_features_scaled, titanic_data_target, train_size = 0.7, test_size = 0.3, random_state = 42)\n",
    "print(features_train.shape, features_test.shape, target_train.shape, target_test.shape, sep = \"\\r\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10. Model the data (1 point)\n",
    "Let's model the data using logistic regression. That's very simple.\n",
    "\n",
    "First, create a logistic regression model (with no custom settings). Then, fit the model using the training features and training target.\n",
    "```python\n",
    "model = LogisticRegression()\n",
    "model.fit(???, ???)\n",
    "```\n",
    "\n",
    "If you wish, you can inspect the model coefficients and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8944f6d44773d414c88c905183f67e8f",
     "grade": false,
     "grade_id": "cell-f0dd6abc403dec0a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bb65e5602e097608eaa7ee18a54a8fe7",
     "grade": true,
     "grade_id": "cell-4afb23030f0e02b5",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11. Score the model (1 point)\n",
    "The default scoring metric for a classification model is **accuracy**. Use `model.score(???, ???)` to get an accuracy score for the model. This should be around 80%.\n",
    "\n",
    "**Note:** Remember to use `features_test` and `target_test`, not the training subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c0c14da725bb4e5b5411416a88aca49e",
     "grade": false,
     "grade_id": "cell-528f747f698aeadf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "score = 0\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b85e5525d594ea45178885015d5939e5",
     "grade": true,
     "grade_id": "cell-0e64bb27e29b0292",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_greater(score, 0)\n",
    "assert_less_equal(score, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that even though it might seem difficult at first, working with models is pretty easy.\n",
    "\n",
    "Feature preparation, train / test split, normalization, extraction of explanatory features vs. target, modelling, testing, and evaluating: these are all parts of the data modelling process. It's the basic idea of **machine learning**.\n",
    "\n",
    "We started from a dataset and we were able to explore, visualize, and model the data. After all this, we have several deliverables: notebook with our research, model (that we might upload somewhere - but that's outside the scope of this lab), (mostly) repeatable research. We have followed a careful and complete process to get to the final results.\n",
    "\n",
    "We can, of course, extend the study. But this is enough for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good luck on the exam! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
